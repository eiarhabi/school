{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file  movies.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading sentence 1000\n",
      "Reading sentence 2000\n",
      "Reading sentence 3000\n",
      "Reading sentence 4000\n",
      "Reading sentence 5000\n",
      "Reading sentence 6000\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import sys\n",
    "\n",
    "def readFileToCorpus(f):\n",
    "\n",
    "    \"\"\" Reads in the text file f which contains one sentence per line.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "\n",
    "        file = open(f, \"r\") # open the input file in read-only mode\n",
    "\n",
    "        i = 0 # this is just a counter to keep track of the sentence numbers\n",
    "\n",
    "        corpus = [] # this will become a list of sentences\n",
    "\n",
    "        print \"reading file \", f\n",
    "\n",
    "        for line in file:\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            sentence = line.split() # split the line into a list of words\n",
    "\n",
    "            corpus.append(sentence) # append this list as an element to the list of sentences\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "\n",
    "                sys.stderr.write(\"Reading sentence \" + str(i) + \"\\n\") # just a status message: str(i) turns the integer i into a string, so that we can concatenate it\n",
    "\n",
    "        return corpus\n",
    "\n",
    "    else:\n",
    "\n",
    "        print \"Error: corpus file \", f, \" does not exist\"  # We should really be throwing an exception here, but for simplicity's sake, this will suffice.\n",
    "\n",
    "        sys.exit() # exit the script\n",
    "def printConcordance(sentence, word_i):\n",
    "\n",
    "    \"\"\" print out the five words preceding word,\n",
    "\n",
    "        the word at position i and the folllowing five words.\"\"\"\n",
    "\n",
    "    if word_i < len(sentence):\n",
    "\n",
    "        start = max(word_i-5, 0)\n",
    "\n",
    "        end = min(word_i+6, len(sentence))\n",
    "\n",
    "        left = ' '.join(sentence[start:word_i])\n",
    "\n",
    "        right = ' '.join(sentence[word_i+1:end])\n",
    "\n",
    "        print left.rjust(40), sentence[word_i].center(10), right.ljust(30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "# Corpus analysis (tokens as class)\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# We use the class Token to point to individual tokens (words) in the corpus.\n",
    "\n",
    "class Token:\n",
    "\n",
    "    def __init__(self, s, w): # we need to initialize each instance of Token:\n",
    "\n",
    "        self.sentence = s # sentence is the index of the sentence (in the corpus)\n",
    "\n",
    "        self.word = w # word is the index of the word (in the sentence)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "# Corpus analysis\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "# Create an index that maps each word to all its positions in the corpus\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "movieCorpus = readFileToCorpus('movies.txt')\n",
    "corpus=movieCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = createCorpusIndex_ClassVersion(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               know if these phrases are    word    for word , but they're        \n",
      "              these phrases are word for    word    , but they're close .         \n",
      "                 i can't recall a single    word    he said that was not          \n",
      "                                       a    word    of advice to mr .             \n",
      "                        yes , i used the    word    'funny' ) thing about this    \n",
      "             disappointing is barely the    word    .                             \n",
      "                      i learned that the    word    \" bitch \" is their            \n",
      "               bitch \" is their favorite    word    , as it seemed to             \n",
      "                  taking the pimp at his    word    .                             \n",
      "                 any modern sense of the    word    , it's time to get            \n",
      "                    deming ( don't say a    word    ) ably captures the dreariness\n",
      "                    for lack of a better    word    , happiness that for the      \n",
      "               and convey to others thru    word    of mouth , so after           \n",
      "              tell without them saying a    word    that there is something going \n",
      "                    a botch job from the    word    go .                          \n",
      "                a junkie for the printed    word    .                             \n",
      "   individuals enthralled by the written    word    , and if you are              \n",
      "                       is far too weak a    word    ) that star wars epsode       \n",
      "                you hanging on his every    word    , but it's not the            \n",
      "                    for lack of a better    word    , \" bad \" deeds               \n",
      "                 is perhaps too strong a    word    .                             \n",
      "                                  as the    word    implies , a masterpiece is    \n",
      "             no television , microwave ,    word    processor , or other technological\n"
     ]
    }
   ],
   "source": [
    "for token in index['word']:\n",
    "    printConcordance(corpus[token.sentence], token.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(',', 7526)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortWords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printStats(corpus):\n",
    "    wordCount=0\n",
    "    sentCount=0\n",
    "    for sent in corpus:\n",
    "        wordCount+=len(sent)\n",
    "        sentCount+=1\n",
    "    print \"Word count:\", wordCount\n",
    "    print \"Sentence count:\", sentCount\n",
    "\n",
    "def getVocab(corpus):\n",
    "    words=[]\n",
    "    for sent in corpus:\n",
    "        for word in sent:\n",
    "            if word not in words:\n",
    "                words.append(word)\n",
    "    words = sorted(words)\n",
    "    return words\n",
    "    \n",
    "def createCorpusIndex_TupleVersion(corpus):\n",
    "    from collections import defaultdict\n",
    "    tupleIndex=defaultdict(list)\n",
    "\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(len(corpus[i])):\n",
    "            tupleIndex[corpus[i][j]].append((i,j))\n",
    "    return tupleIndex\n",
    "        \n",
    "def printWordFrequencies_TupleVersion(index, vocab):\n",
    "    sortTuples = sorted(index.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    sortWords = [(x[0], len(x[1])) for x in sortTuples]\n",
    "    print sortWords\n",
    "\n",
    "def printCorpusConcordance_TupleVersion(word, corpus, index):\n",
    "    for token in index[word]:\n",
    "        printConcordance(corpus[token[0]], token[1])\n",
    "\n",
    "def createCorpusIndex_ClassVersion(corpus):\n",
    "    from collections import defaultdict\n",
    "    tupleIndex=defaultdict(list)\n",
    "\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(len(corpus[i])):\n",
    "            tupleIndex[corpus[i][j]].append(Token(i,j))\n",
    "    return tupleIndex\n",
    "\n",
    "def printWordFrequencies_ClassVersion(index, vocab):\n",
    "    sortTokens = sorted(index.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    sortWords = [(x[0], len(x[1])) for x in sortTuples]\n",
    "    print sortWords\n",
    "\n",
    "def printCorpusConcordance_ClassVersion(word, corpus, index):\n",
    "    for token in index[word]:\n",
    "        printConcordance(corpus[token.sentence], token.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
